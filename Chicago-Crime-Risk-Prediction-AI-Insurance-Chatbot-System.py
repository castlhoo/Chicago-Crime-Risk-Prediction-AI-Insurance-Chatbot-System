# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1e0lqywUKZeaSdoyAZpedzHBeJNWRvoXb
"""

# Java 설치
!apt-get install openjdk-8-jdk-headless -qq > /dev/null

# Spark 다운로드
!wget -q https://archive.apache.org/dist/spark/spark-3.4.1/spark-3.4.1-bin-hadoop3.tgz
!tar xf spark-3.4.1-bin-hadoop3.tgz

# PySpark 설치
!pip install pyspark

# 환경 변수 설정
import os
os.environ["JAVA_HOME"] = "/usr/lib/jvm/java-8-openjdk-amd64"
os.environ["SPARK_HOME"] = "/content/spark-3.4.1-bin-hadoop3"

# Spark 세션 생성
from pyspark.sql import SparkSession
spark = SparkSession.builder \
    .appName("Chicago Crime Analysis") \
    .master("local[*]") \
    .getOrCreate()

from google.colab import drive
drive.mount('/content/drive')

import gdown

file_id = "1dUjFesnvqHaZvGxYI13IGtg5ptFJooV5"

gdown.download(
    "https://drive.google.com/file/d/1dUjFesnvqHaZvGxYI13IGtg5ptFJooV5/view?usp=drive_link",
    "chicago_crime_data.csv",
    quiet=False,
    fuzzy=True
)

chicago_df = spark.read.csv("chicago_crime_data.csv", header=True, inferSchema=True)
chicago_df.printSchema()

chicago_df.limit(10).show()

chicago_df.describe()

from pyspark.sql.functions import col

chicago_df_copied = chicago_df.select('*')

# 1. Drop unecessary columns
chicago_df_copied = chicago_df_copied.drop('Year', 'Updated On')
chicago_df_copied.show()

# 2. PreProcessing Data
## 2-1. Create temporal features from Date
from pyspark.sql.functions import to_timestamp, month, hour, dayofweek, when, col

# To timestamp type
chicago_df_copied = chicago_df_copied.withColumn(
    "DateTime",
    to_timestamp("Date", "M/d/yyyy H:mm")
)

chicago_df_copied = chicago_df_copied.withColumn("Hour", hour("DateTime"))
chicago_df_copied = chicago_df_copied.withColumn("Weekday", dayofweek("DateTime"))
chicago_df_copied = chicago_df_copied.withColumn("Month", month("DateTime"))


chicago_df_copied = chicago_df_copied.withColumn(
    "Time_Risk",
    when((col("Hour") >= 6) & (col("Hour") < 18), "DAY_TIME")
    .when((col("Hour") >= 18) & (col("Hour") < 22), "EVENING")
    .otherwise("NIGHT")
)

chicago_df_copied = chicago_df_copied.withColumn(
    "Season",
    when(col("Month").isin([12, 1, 2]), "WINTER")
    .when(col("Month").isin([3, 4, 5]), "SPRING")
    .when(col("Month").isin([6, 7, 8]), "SUMMER")
    .otherwise("FALL")
)

chicago_df_copied = chicago_df_copied.withColumn(
    "Day_Type",
    when(col("Weekday").isin([1, 7]), "WEEKEND")
    .otherwise("WEEKDAY")
)

chicago_df_copied.show()

chicago_df_copied = chicago_df_copied.drop("Date")

chicago_df_copied.printSchema()

# 2-2. In block columns, remain only street name
from pyspark.sql.functions import split

chicago_df_copied = chicago_df_copied.withColumn("Street", split("Block"," ")[2])
chicago_df_copied.select("*").show()

chicago_df_copied = chicago_df_copied.drop("Block")

# 2-3. Categorize location Description
def categorize_location(desc):
    desc = str(desc).lower()

    if any(x in desc for x in ['residence', 'apartment', 'yard', 'porch', 'garage', 'vestibule', 'coach house', 'rooming house', 'cha hallway', 'cha apartment', 'cha play', 'cha parking', 'cha lobby', 'cha stairwell', 'cha elevator', 'cha breezeway', 'cha grounds']):
        return 'RESIDENTIAL'
    elif any(x in desc for x in ['store', 'shop', 'retail', 'restaurant', 'tavern', 'bar', 'motel', 'hotel', 'liquor store', 'gas station', 'atm', 'bank', 'funeral', 'laundry', 'cleaning', 'dealership', 'currency exchange', 'beauty salon', 'barber', 'appliance']):
        return 'COMMERCIAL'
    elif any(x in desc for x in ['cta', 'station', 'platform', 'train', 'bus', 'taxi', 'vehicle', 'garage', 'parking lot', 'airport', 'delivery truck', 'ride share', 'expressway', 'tracks', 'highway', 'uber', 'lyft', 'transportation system', 'trolley']):
        return 'TRANSPORT'
    elif any(x in desc for x in ['street', 'sidewalk', 'park', 'property', 'alley', 'bridge', 'river', 'lake', 'forest', 'beach', 'lagoon', 'riverbank', 'lakefront', 'wooded', 'gangway', 'sewer', 'prairie']):
        return 'PUBLIC'
    elif any(x in desc for x in ['school', 'college', 'university', 'grammar school', 'high school', 'school yard', 'day care']):
        return 'EDUCATION'
    elif any(x in desc for x in ['hospital', 'medical', 'dental', 'nursing', 'retirement', 'ymca', 'animal hospital', 'funeral']):
        return 'MEDICAL'
    elif any(x in desc for x in ['police', 'jail', 'lock-up', 'courthouse', 'government', 'fire station', 'federal', 'county']):
        return 'GOVERNMENT'
    elif any(x in desc for x in ['warehouse', 'factory', 'manufacturing', 'construction', 'trucking', 'appliance', 'cleaners', 'garage/auto', 'junk yard', 'loading dock']):
        return 'INDUSTRIAL'
    elif any(x in desc for x in ['club', 'athletic', 'pool', 'sports arena', 'bowling', 'movie', 'theater', 'lounge', 'banquet', 'gym']):
        return 'RECREATIONAL'
    else:
        return 'OTHER'

from pyspark.sql.functions import udf,col
from pyspark.sql.types import StringType

cat_location = udf(lambda x : categorize_location(x), StringType())

chicago_df_copied = chicago_df_copied.withColumn('Location_Category', cat_location(col('Location Description')))

chicago_df_copied = chicago_df_copied.drop("Location Description")

chicago_df_copied.show()

# 2-4. Mapping Community Area with actual name
from pyspark.sql.functions import when, col

chicago_df_copied = chicago_df_copied.withColumn("CA_Name",
    when(col("Community Area") == 1, "ROGERS PARK")
    .when(col("Community Area") == 2, "WEST RIDGE")
    .when(col("Community Area") == 3, "UPTOWN")
    .when(col("Community Area") == 4, "LINCOLN SQUARE")
    .when(col("Community Area") == 5, "NORTH CENTER")
    .when(col("Community Area") == 6, "LAKE VIEW")
    .when(col("Community Area") == 7, "LINCOLN PARK")
    .when(col("Community Area") == 8, "NEAR NORTH SIDE")
    .when(col("Community Area") == 9, "EDISON PARK")
    .when(col("Community Area") == 10, "NORWOOD PARK")
    .when(col("Community Area") == 11, "JEFFERSON PARK")
    .when(col("Community Area") == 12, "FOREST GLEN")
    .when(col("Community Area") == 13, "NORTH PARK")
    .when(col("Community Area") == 14, "ALBANY PARK")
    .when(col("Community Area") == 15, "PORTAGE PARK")
    .when(col("Community Area") == 16, "IRVING PARK")
    .when(col("Community Area") == 17, "DUNNING")
    .when(col("Community Area") == 18, "MONTCLARE")
    .when(col("Community Area") == 19, "BELMONT CRAGIN")
    .when(col("Community Area") == 20, "HERMOSA")
    .when(col("Community Area") == 21, "AVONDALE")
    .when(col("Community Area") == 22, "LOGAN SQUARE")
    .when(col("Community Area") == 23, "HUMBOLDT PARK")
    .when(col("Community Area") == 24, "WEST TOWN")
    .when(col("Community Area") == 25, "AUSTIN")
    .when(col("Community Area") == 26, "WEST GARFIELD PARK")
    .when(col("Community Area") == 27, "EAST GARFIELD PARK")
    .when(col("Community Area") == 28, "NEAR WEST SIDE")
    .when(col("Community Area") == 29, "NORTH LAWNDALE")
    .when(col("Community Area") == 30, "SOUTH LAWNDALE")
    .when(col("Community Area") == 31, "LOWER WEST SIDE")
    .when(col("Community Area") == 32, "LOOP")
    .when(col("Community Area") == 33, "NEAR SOUTH SIDE")
    .when(col("Community Area") == 34, "ARMOUR SQUARE")
    .when(col("Community Area") == 35, "DOUGLAS")
    .when(col("Community Area") == 36, "OAKLAND")
    .when(col("Community Area") == 37, "FULLER PARK")
    .when(col("Community Area") == 38, "GRAND BOULEVARD")
    .when(col("Community Area") == 39, "KENWOOD")
    .when(col("Community Area") == 40, "WASHINGTON PARK")
    .when(col("Community Area") == 41, "HYDE PARK")
    .when(col("Community Area") == 42, "WOODLAWN")
    .when(col("Community Area") == 43, "SOUTH SHORE")
    .when(col("Community Area") == 44, "CHATHAM")
    .when(col("Community Area") == 45, "AVALON PARK")
    .when(col("Community Area") == 46, "SOUTH CHICAGO")
    .when(col("Community Area") == 47, "BURNSIDE")
    .when(col("Community Area") == 48, "CALUMET HEIGHTS")
    .when(col("Community Area") == 49, "ROSELAND")
    .when(col("Community Area") == 50, "PULLMAN")
    .when(col("Community Area") == 51, "SOUTH DEERING")
    .when(col("Community Area") == 52, "EAST SIDE")
    .when(col("Community Area") == 53, "WEST PULLMAN")
    .when(col("Community Area") == 54, "RIVERDALE")
    .when(col("Community Area") == 55, "HEGEWISCH")
    .when(col("Community Area") == 56, "GARFIELD RIDGE")
    .when(col("Community Area") == 57, "ARCHER HEIGHTS")
    .when(col("Community Area") == 58, "BRIGHTON PARK")
    .when(col("Community Area") == 59, "MCKINLEY PARK")
    .when(col("Community Area") == 60, "BRIDGEPORT")
    .when(col("Community Area") == 61, "NEW CITY")
    .when(col("Community Area") == 62, "WEST ELSDON")
    .when(col("Community Area") == 63, "GAGE PARK")
    .when(col("Community Area") == 64, "CLEARING")
    .when(col("Community Area") == 65, "WEST LAWN")
    .when(col("Community Area") == 66, "CHICAGO LAWN")
    .when(col("Community Area") == 67, "WEST ENGLEWOOD")
    .when(col("Community Area") == 68, "ENGLEWOOD")
    .when(col("Community Area") == 69, "GREATER GRAND CROSSING")
    .when(col("Community Area") == 70, "ASHBURN")
    .when(col("Community Area") == 71, "AUBURN GRESHAM")
    .when(col("Community Area") == 72, "BEVERLY")
    .when(col("Community Area") == 73, "WASHINGTON HEIGHTS")
    .when(col("Community Area") == 74, "MOUNT GREENWOOD")
    .when(col("Community Area") == 75, "MORGAN PARK")
    .when(col("Community Area") == 76, "OHARE")
    .when(col("Community Area") == 77, "EDGEWATER")
    .otherwise("UNKNOWN")
)

from pyspark.sql.functions import when, col

chicago_df_copied = chicago_df_copied.withColumn("Region",
    # Central
    when(col("Community Area").isin([8, 32, 33]), "Central")

    # Far North Side
    .when(col("Community Area").isin([1, 2, 3, 4, 5, 9, 10, 11, 12, 13, 14, 77]), "Far North Side")

    # Far Southeast Side
    .when(col("Community Area").isin([45, 46, 47, 48, 51, 52, 55]), "Far Southeast Side")

    # Far Southwest Side
    .when(col("Community Area").isin([56, 57, 58, 70, 72, 73, 74, 75]), "Far Southwest Side")

    # North Side
    .when(col("Community Area").isin([6, 7, 21, 22]), "North Side")

    # Northwest Side
    .when(col("Community Area").isin([15, 16, 17, 18, 19, 20, 76]), "Northwest Side")

    # South Side
    .when(col("Community Area").isin([34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 49, 50, 53, 54, 69]), "South Side")

    # Southwest Side
    .when(col("Community Area").isin([59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 71]), "Southwest Side")

    # West Side
    .when(col("Community Area").isin([23, 24, 25, 26, 27, 28, 29, 30, 31]), "West Side")

    .otherwise("Unknown")
)

chicago_df_copied.show()

# 2-5. Categorize Crime Type (Primary Type)
def categorize_crime(primary_type):
    primary_type = str(primary_type).upper()

    if primary_type in ['THEFT', 'BURGLARY', 'MOTOR VEHICLE THEFT', 'CRIMINAL DAMAGE', 'DECEPTIVE PRACTICE', 'ARSON']:
        return 'PROPERTY'

    elif primary_type in ['BATTERY', 'ASSAULT', 'ROBBERY', 'HOMICIDE', 'KIDNAPPING', 'INTIMIDATION']:
        return 'VIOLENT'

    elif primary_type in ['WEAPONS VIOLATION', 'CONCEALED CARRY LICENSE VIOLATION']:
        return 'WEAPONS'

    elif primary_type in ['SEX OFFENSE', 'CRIMINAL SEXUAL ASSAULT', 'OFFENSE INVOLVING CHILDREN', 'PROSTITUTION', 'STALKING']:
        return 'SEX_CRIME'

    elif primary_type in ['NARCOTICS', 'OTHER NARCOTIC VIOLATION']:
        return 'DRUG'

    elif primary_type in ['OTHER OFFENSE', 'CRIMINAL TRESPASS', 'PUBLIC PEACE VIOLATION', 'INTERFERENCE WITH PUBLIC OFFICER', 'LIQUOR LAW VIOLATION', 'OBSCENITY', 'PUBLIC INDECENCY', 'GAMBLING', 'HUMAN TRAFFICKING', 'NON-CRIMINAL']:
        return 'PUBLIC_ORDER'

    else:
        return 'PUBLIC_ORDER'

from pyspark.sql.functions import udf,col
from pyspark.sql.types import StringType

cat_crime = udf(lambda x : categorize_crime(x), StringType())

chicago_df_copied = chicago_df_copied.withColumn('Crime_Category', cat_crime(col('Primary Type')))

chicago_df_copied.show()

# 2-5. Additional Feature Engineering
from pyspark.sql.functions import count, min as spark_min, max as spark_max, mean, when, col

# 1. Calculate the risk of area
area_counts = chicago_df_copied.groupBy('CA_Name').count()
min_count = area_counts.select(spark_min("count")).collect()[0][0]
max_count = area_counts.select(spark_max("count")).collect()[0][0]

risk_scores = area_counts.withColumn(
    "area_risk_score",
    ((col("count") - min_count) / (max_count - min_count)) * 100
).select("CA_Name", "area_risk_score")

# 2. Calculate the rate of crime in area
arrest_rates = chicago_df_copied.withColumn(
    "Arrest_numeric",
    when(col("Arrest") == True, 1).otherwise(0)
).groupBy("CA_Name").agg(
    mean("Arrest_numeric").alias("arrest_rate")
)

chicago_df_copied = chicago_df_copied.join(risk_scores, on="CA_Name", how="left")
chicago_df_copied = chicago_df_copied.join(arrest_rates, on="CA_Name", how="left")

# 2-5. Additional Feature Engineering
from pyspark.sql.functions import udf
from pyspark.sql.functions import round as spark_round
from pyspark.sql.types import IntegerType, DoubleType

# 1. Crime severity Score
def crime_sev_score(primary_type):
    sev_map = {
        'HOMICIDE': 10, 'CRIMINAL SEXUAL ASSAULT': 9,
        'KIDNAPPING': 8, 'ROBBERY': 7, 'ASSAULT': 6,
        'BATTERY': 5, 'BURGLARY': 4, 'THEFT': 3,
        'CRIMINAL DAMAGE': 2, 'OTHER OFFENSE': 1
    }
    return sev_map.get(primary_type, 1)

# 2. location risk score
def location_risk_score(location_category):
    risk_map = {
        'RESIDENTIAL': 1.2, 'COMMERCIAL': 1.5,
        'PUBLIC': 1.3, 'TRANSPORT': 1.1
    }
    return risk_map.get(location_category, 1.0)

# UDF
sev_udf = udf(crime_sev_score, IntegerType())
location_risk_udf = udf(location_risk_score, DoubleType())

chicago_df_copied = chicago_df_copied \
    .withColumn("crime_severity", sev_udf(col("Primary Type"))) \
    .withColumn("location_risk", location_risk_udf(col("Location_Category"))) \
    .withColumn("total_risk_score", spark_round(col("crime_severity") * col("location_risk"),1))

chicago_df_copied.show()

# 3. Null Value Check

for column_name in chicago_df_copied.columns:
    null_count = chicago_df_copied.filter(col(column_name).isNull()).count()
    if null_count > 0:
        print(f"{column_name} : {null_count}")

# 1. Ward
ward_data = chicago_df_copied.groupBy('Ward').count().orderBy('count', ascending=False)
display(ward_data)

# ward -> about location, fillna with mode
from pyspark.sql.functions import col

chicago_df_copied = chicago_df_copied.fillna({"Ward": 42})

# 2. coordinate
display(chicago_df_copied.select("X Coordinate"))

from pyspark.sql.functions import expr, avg, stddev, min, max

chicago_df_copied.select(
    avg("X Coordinate").alias("mean_x"),
    expr("percentile_approx(`X Coordinate`, 0.5)").alias("median_x"),
    stddev("X Coordinate").alias("std_x"),
    min("X Coordinate").alias("min_x"),
    max("X Coordinate").alias("max_x")
).show()

from pyspark.sql.functions import expr

median = chicago_df_copied.select(expr("percentile_approx(`X Coordinate`, 0.5)")).collect()[0][0]

chicago_df_copied = chicago_df_copied.fillna(value=median, subset=['X Coordinate'])

display(chicago_df_copied.select("Y Coordinate"))

from pyspark.sql.functions import expr, avg, stddev, min, max

chicago_df_copied.select(
    avg("Y Coordinate").alias("mean_y"),
    expr("percentile_approx(`Y Coordinate`, 0.5)").alias("median_y"),
    stddev("Y Coordinate").alias("std_y"),
    min("Y Coordinate").alias("min_y"),
    max("Y Coordinate").alias("max_y")
).show()

from pyspark.sql.functions import expr

median = chicago_df_copied.select(expr("percentile_approx(`Y Coordinate`, 0.5)")).collect()[0][0]

chicago_df_copied = chicago_df_copied.fillna(value=median, subset=['Y Coordinate'])

# 3. Latitude
display(chicago_df_copied.select('Latitude'))

from pyspark.sql.functions import expr, avg, stddev, min, max

chicago_df_copied.select(
    avg("Latitude").alias("mean_L"),
    expr("percentile_approx(`Latitude`, 0.5)").alias("median_L"),
    stddev("Latitude").alias("std_L"),
    min("Latitude").alias("min_L"),
    max("Latitude").alias("max_L")
).show()

mean_lat = chicago_df_copied.select(avg("Latitude")).collect()[0][0]
chicago_df_copied = chicago_df_copied.fillna(value=mean_lat, subset=['Latitude'])

# 4. Longitude
display(chicago_df_copied.select(['Longitude']))

from pyspark.sql.functions import expr, avg, stddev, min, max

chicago_df_copied.select(
    avg("Longitude").alias("mean_L"),
    expr("percentile_approx(`Longitude`, 0.5)").alias("median_L"),
    stddev("Longitude").alias("std_L"),
    min("Longitude").alias("min_L"),
    max("Longitude").alias("max_L")
).show()

mean_long = chicago_df_copied.select(avg("Longitude")).collect()[0][0]
chicago_df_copied = chicago_df_copied.fillna(value=mean_long, subset=['Longitude'])

# 5.Location
from pyspark.sql.functions import concat, lit

chicago_df_copied = chicago_df_copied.drop("Location").withColumn(
    "Location",
    concat(lit("("), col("Latitude"), lit(", "), col("Longitude"), lit(")"))
)

for column_name in chicago_df_copied.columns:
    null_count = chicago_df_copied.filter(col(column_name).isNull()).count()
    if null_count > 0:
        print(f"{column_name} : {null_count}")

# Check Outlier
chicago_df_copied.printSchema()

# 1. Location
# 1. IQR
lat_q1 = chicago_df_copied.select(expr("percentile_approx(Latitude, 0.25)")).collect()[0][0]
lat_q3 = chicago_df_copied.select(expr("percentile_approx(Latitude, 0.75)")).collect()[0][0]
lat_iqr = lat_q3 - lat_q1
lat_lower = lat_q1 - 1.5 * lat_iqr
lat_upper = lat_q3 + 1.5 * lat_iqr

lng_q1 = chicago_df_copied.select(expr("percentile_approx(Longitude, 0.25)")).collect()[0][0]
lng_q3 = chicago_df_copied.select(expr("percentile_approx(Longitude, 0.75)")).collect()[0][0]
lng_iqr = lng_q3 - lng_q1
lng_lower = lng_q1 - 1.5 * lng_iqr
lng_upper = lng_q3 + 1.5 * lng_iqr

print(f"Latitude Normal Range: {lat_lower:.4f} ~ {lat_upper:.4f}")
print(f"Longitude Normal Range: {lng_lower:.4f} ~ {lng_upper:.4f}")

# 2
lat_outliers = chicago_df_copied.filter((col("Latitude") < lat_lower) | (col("Latitude") > lat_upper)).count()
lng_outliers = chicago_df_copied.filter((col("Longitude") < lng_lower) | (col("Longitude") > lng_upper)).count()
coord_zero = chicago_df_copied.filter((col("X Coordinate") == 0) | (col("Y Coordinate") == 0)).count()

print(f"Latitude Outlier: {lat_outliers}")
print(f"Longitude Outlier: {lng_outliers}")
print(f"Zero: {coord_zero}")

# 3
total_outliers = chicago_df_copied.filter(
    (col("Latitude") < lat_lower) | (col("Latitude") > lat_upper) |
    (col("Longitude") < lng_lower) | (col("Longitude") > lng_upper) |
    (col("X Coordinate") == 0) | (col("Y Coordinate") == 0)
).count()

print(f"Count of Outlier: {total_outliers}")

# 4
total_count = chicago_df_copied.count()
print(f"Overall Data: {total_count}")
print(f"Percentage of Outlier: {total_outliers/total_count*100:.2f}%")

chicago_df_copied = chicago_df_copied.filter(
    (col("Latitude") >= 41.5644) & (col("Latitude") <= 42.1136) &
    (col("Longitude") >= -87.8325) & (col("Longitude") <= -87.5038) &
    (col("X Coordinate") != 0) & (col("Y Coordinate") != 0)
)

# 2. Month & Date
print(chicago_df_copied.filter((col("Month") < 0) | (col("Month") > 12)).count())

from pyspark.sql.functions import year

chicago_df_copied.groupBy(year("DateTime").alias("Year")).count().orderBy("Year").show()

non_2022_count = chicago_df_copied.filter(year("DateTime") != 2022).count()
print(non_2022_count)

chicago_df_copied = chicago_df_copied.filter(year("DateTime") == 2022)

# ML Model for recommending insurance commodity
chicago_df_copied.show()

chicago_df_model = chicago_df_copied.select("*").cache()

columns_to_remove = [
    "ID", "Case Number", "IUCR", "Description",
    "Beat", "District", "Ward", "Community Area",
    "X Coordinate", "Y Coordinate", "DateTime",
    "Location", "Latitude", "Longitude", "FBI Code"
]

keep_columns = [col for col in chicago_df_model.columns if col not in columns_to_remove]

chicago_df_model = chicago_df_model.select(*keep_columns)

chicago_df_model.describe().show()

chicago_df_model.describe()

## 1. change type
type_mapping = {
    "Hour": "integer",
    "Weekday": "integer",
    "Month": "integer",
    "crime_severity": "integer",

    "area_risk_score": "double",
    "arrest_rate": "double",
    "location_risk": "double",
    "total_risk_score": "double",
}

for col_name, col_type in type_mapping.items():
    chicago_df_model = chicago_df_model.withColumn(col_name, col(col_name).cast(col_type))

chicago_df_model.printSchema()

## 2.Check Outlier

# Hour
hour_outliers = chicago_df_model.filter(
    (col("Hour") < 0) | (col("Hour") > 23)
).count()
print(hour_outliers)

# Month
month_outliers = chicago_df_model.filter(
    (col("Month") < 1) | (col("Month") > 12)
).count()
print(month_outliers)

# arrest_rate
arrest_outliers = chicago_df_model.filter(
    (col("arrest_rate") < 0) | (col("arrest_rate") > 1)
).count()
print(arrest_outliers)

# Outlier
chicago_df_model.select("area_risk_score", "total_risk_score").orderBy(
    col("area_risk_score").desc()
).show(5)

## 3. Check miss value
from pyspark.sql.functions import col, isnan, when, count

chicago_df_model.select([
    count(when(col(c).isNull(), c)).alias(f"{c}_null_count")
    for c in chicago_df_model.columns
]).show()

## 4. Encoding
from pyspark.ml.feature import StringIndexer, OneHotEncoder
from pyspark.ml import Pipeline
from pyspark.sql.functions import when, col

categorial_features = [
    'CA_Name', 'Location_Category', 'Time_Risk', 'Season',
    'Day_Type', 'Region', 'Crime_Category'
]

encoding_features = [
    'CA_Name', 'Location_Category', 'Time_Risk', 'Season',
    'Day_Type', 'Region'
]

chicago_df_model = chicago_df_model.withColumn(
    "Arrest_int",
    when(col("Arrest") == True, 1).otherwise(0)
)

chicago_df_model = chicago_df_model.withColumn(
    "Domestic_int",
    when(col("Domestic") == True, 1).otherwise(0)
)

indexers = [
    StringIndexer(inputCol = col, outputCol = col + "_index", handleInvalid = "keep")
    for col in encoding_features
]

encoders = [
    OneHotEncoder(inputCol = col + "_index", outputCol = col + "_encoded")
    for col in encoding_features
]

encoding_pipeline = Pipeline(stages = indexers + encoders)
chicago_df_model = encoding_pipeline.fit(chicago_df_model).transform(chicago_df_model)

numeric_features = [
    "Hour", "Month", "Weekday", "crime_severity",
    "area_risk_score", "arrest_rate", "location_risk", "total_risk_score",
    "Arrest_int", "Domestic_int"
]

encoded_features = [col + "_encoded" for col in encoding_features]
all_features = numeric_features + encoded_features
target = "Crime_Category"

print(all_features)

from pyspark.ml.feature import StringIndexer

label_indexer = StringIndexer(
    inputCol="Crime_Category",
    outputCol="label",
    handleInvalid="keep"
)

chicago_df_model = label_indexer.fit(chicago_df_model).transform(chicago_df_model)

chicago_df_model.select("Crime_Category", "label").distinct().orderBy("label").show()

chicago_df_model.show()

# VectorAssembler
from pyspark.ml.feature import VectorAssembler

assembler = VectorAssembler(
    inputCols = all_features,
    outputCol = "features"
)

chicago_df_final = assembler.transform(chicago_df_model)

# Data Dividing
train_data, tmp_data = chicago_df_final.randomSplit([0.8, 0.2], seed = 42)
val_data, test_data = tmp_data.randomSplit([0.5, 0.5], seed = 42)

chicago_df_final.groupBy("Crime_Category").count().orderBy("count", ascending=False).show()
train_data.groupBy("Crime_Category").count().orderBy("count", ascending=False).show()
val_data.groupBy("Crime_Category").count().orderBy("count", ascending=False).show()

# 1. Random Forest
from pyspark.ml.classification import RandomForestClassifier
from pyspark.ml.evaluation import MulticlassClassificationEvaluator
import time

# 1-1. Create basic Random Forest model with default parameters
rf_basic = RandomForestClassifier(
    featuresCol="features",
    labelCol='label',
    numTrees=20,
    maxDepth=5,
    seed = 42
)

# 1-2. Train the model
start_time = time.time()
rf_basic_model = rf_basic.fit(train_data)
rf_basic_train_time = time.time() - start_time

# 1-3. Make predictions on train and validation data
rf_basic_train_pred = rf_basic_model.transform(train_data)
rf_basic_val_pred = rf_basic_model.transform(val_data)

# 1-4. Setup evaluators
evaluator_acc = MulticlassClassificationEvaluator(
    labelCol="label",
    predictionCol="prediction",
    metricName="accuracy"
)

evaluator_f1 = MulticlassClassificationEvaluator(
    labelCol="label",
    predictionCol="prediction",
    metricName="f1"
)

# 1-5. Evaluate performance
rf_basic_train_acc = evaluator_acc.evaluate(rf_basic_train_pred)
rf_basic_val_acc = evaluator_acc.evaluate(rf_basic_val_pred)
rf_basic_train_f1 = evaluator_f1.evaluate(rf_basic_train_pred)
rf_basic_val_f1 = evaluator_f1.evaluate(rf_basic_val_pred)

# 1-6. Check overfitting
rf_basic_overfitting = rf_basic_train_acc - rf_basic_val_acc

# 1-7. Print results
print(f"Training time: {rf_basic_train_time:.2f} seconds")
print(f"Train accuracy: {rf_basic_train_acc:.4f}")
print(f"Validation accuracy: {rf_basic_val_acc:.4f}")
print(f"Train F1: {rf_basic_train_f1:.4f}")
print(f"Validation F1: {rf_basic_val_f1:.4f}")
print(f"Overfitting degree: {rf_basic_overfitting:.4f}")

# Overfitting assessment
if rf_basic_overfitting < 0.05:
    print("No overfitting")
elif rf_basic_overfitting < 0.10:
    print("Slight overfitting")
else:
    print("Severe overfitting")

# 2. Random Forest Hyperopt Tuning
from hyperopt import fmin, tpe, hp, STATUS_OK, Trials
import time

# 2-1. Define hyperparameter search space
rf_space = {
    'numTrees': hp.choice('numTrees', [50, 100, 150]),
    'maxDepth': hp.choice('maxDepth', [8, 12, 15]),
    'minInstancesPerNode': hp.choice('minInstancesPerNode', [1, 5]),
    'subsamplingRate': hp.uniform('subsamplingRate', 0.8, 1.0),
    'featureSubsetStrategy': hp.choice('featureSubsetStrategy', ['auto', 'sqrt'])
}

# 2-2. Define objective function
def rf_objective(params):
    rf = RandomForestClassifier(
        featuresCol="features",
        labelCol="label",
        numTrees=int(params['numTrees']),
        maxDepth=int(params['maxDepth']),
        minInstancesPerNode=int(params['minInstancesPerNode']),
        subsamplingRate=params['subsamplingRate'],
        featureSubsetStrategy=params['featureSubsetStrategy'],
        seed=42
    )

    # Train model
    model = rf.fit(train_data)

    # Evaluate on validation data
    predictions = model.transform(val_data)
    accuracy = evaluator_acc.evaluate(predictions)

    # Return negative accuracy (hyperopt minimizes)
    return {'loss': -accuracy, 'status': STATUS_OK}

# 2-3. Run hyperopt optimization
trials = Trials()
start_time = time.time()

best_params = fmin(
    fn=rf_objective,
    space=rf_space,
    algo=tpe.suggest,
    max_evals=7,
    trials=trials
)

hyperopt_time = time.time() - start_time

# 2-4. Print best parameters
print(f"Hyperopt completed in {hyperopt_time:.2f} seconds")

# Convert indices to actual values
param_mapping = {
    'numTrees': [50, 100, 150],
    'maxDepth': [8, 12, 15],
    'minInstancesPerNode': [1, 5],
    'featureSubsetStrategy': ['auto', 'sqrt']
}

print("Best parameters:")
for param, index_value in best_params.items():
    if param in param_mapping:
        actual_value = param_mapping[param][int(index_value)]
        print(f"  {param}: {actual_value}")
    else:
        print(f"  {param}: {index_value:.3f}")

# 3. Random Forest Best Model with optimized parameters
rf_best = RandomForestClassifier(
    featuresCol="features",
    labelCol="label",
    numTrees=50,
    maxDepth=15,
    minInstancesPerNode=5,
    subsamplingRate=0.833,
    featureSubsetStrategy='sqrt',
    seed=42
)

# Train the best model
start_time = time.time()
rf_best_model = rf_best.fit(train_data)
rf_best_train_time = time.time() - start_time

# Evaluate on train, validation, and test
rf_best_train_pred = rf_best_model.transform(train_data)
rf_best_val_pred = rf_best_model.transform(val_data)
rf_best_test_pred = rf_best_model.transform(test_data)

rf_best_train_acc = evaluator_acc.evaluate(rf_best_train_pred)
rf_best_val_acc = evaluator_acc.evaluate(rf_best_val_pred)
rf_best_test_acc = evaluator_acc.evaluate(rf_best_test_pred)

rf_best_train_f1 = evaluator_f1.evaluate(rf_best_train_pred)
rf_best_val_f1 = evaluator_f1.evaluate(rf_best_val_pred)
rf_best_test_f1 = evaluator_f1.evaluate(rf_best_test_pred)

print(f"RF Best Results:")
print(f"Train accuracy: {rf_best_train_acc:.4f}")
print(f"Validation accuracy: {rf_best_val_acc:.4f}")
print(f"Test accuracy: {rf_best_test_acc:.4f}")
print(f"Train F1: {rf_best_train_f1:.4f}")
print(f"Validation F1: {rf_best_val_f1:.4f}")
print(f"Test F1: {rf_best_test_f1:.4f}")
print(f"Overfitting: {rf_best_train_acc - rf_best_val_acc:.4f}")

#3, Convert data for LGBM and XGBoost

try:
    columns = chicago_df_copied.columns
    print(f"Columns: {columns}")

    data_rows = chicago_df_copied.collect()
    print(f"Data collected: {len(data_rows)} rows")

    # Convert to pandas
    import pandas as pd
    chicago_pandas = pd.DataFrame(data_rows, columns=columns)

    print(f"Pandas conversion done")

except Exception as e:
    print(f"Collect method failed: {e}")

chicago_pandas.dtypes

# 4. Data Preprocessing
features_for_ml = [
    # Categorical features (need encoding)
    'CA_Name', 'Primary Type', 'Location_Category', 'Time_Risk', 'Season', 'Day_Type', 'Region',

    # Numerical features
    'Hour', 'Month', 'Weekday', 'crime_severity', 'area_risk_score',
    'arrest_rate', 'location_risk', 'total_risk_score',

    # Boolean features (convert to int)
    'Arrest', 'Domestic',

    # Target
    'Crime_Category'
]

chicago_ml = chicago_pandas[features_for_ml].copy()
chicago_ml.head()

# 4-1. Change Data type
chicago_ml['Arrest'] = chicago_ml['Arrest'].map({True: 1, False: 0})
chicago_ml['Domestic'] = chicago_ml['Domestic'].map({True: 1, False: 0})

# 4-2. Check Missing Value
missing_values = chicago_ml.isnull().sum()
print(missing_values)

# 4-3. Check Outlier
numeric_cols = ['Hour', 'Month', 'Weekday', 'crime_severity', 'area_risk_score',
               'arrest_rate', 'location_risk', 'total_risk_score']

def detect_outliers(df, columns):
    outlier_summary = {}

    for col in columns:
        q1 = df[col].quantile(0.25)
        q3 = df[col].quantile(0.75)
        iqr = q3 - q1

        lower_bound = q1 - 1.5 * iqr
        upper_bound = q3 + 1.5 * iqr

        # Find outliers
        outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]
        outlier_count = len(outliers)

        outlier_summary[col] = {
            'count': outlier_count,
            'total_rows': len(df)
        }

        print(f"{col}:")
        print(f"  Outliers: {outlier_count} / {len(df)}")
        print(f"  Range: [{lower_bound:.3f}, {upper_bound:.3f}]")
        print()

    return outlier_summary

# Execute outlier detection
outlier_results = detect_outliers(chicago_ml, numeric_cols)
# result -> arrest_rate, location_risk, total_risk_store = it has own data value, so dont need to change

# 4-3. Check Distribution
from scipy import stats
import matplotlib.pyplot as plt

numeric_cols = ['Hour', 'Month', 'Weekday', 'crime_severity', 'area_risk_score',
               'arrest_rate', 'location_risk', 'total_risk_score']

def check_distribution(df, columns):
  for col in columns:
    skewness = stats.skew(df[col])
    print(f'{col} : {skewness:.3f}')

  fig, axes = plt.subplots(nrows=2, ncols=4, figsize=(16, 8))
  axes = axes.flatten()

  for i, col in enumerate(columns):
      skewness = stats.skew(df[col])
      axes[i].hist(df[col], bins=30, alpha=0.7, color='skyblue')
      axes[i].set_title(f'{col}\nSkew: {skewness:.2f}')
      axes[i].grid(True, alpha=0.3)

  plt.tight_layout()
  plt.show()

print(check_distribution(chicago_ml, numeric_cols))
# result -> dont need to transform log

# 4-4. One-hot encoding

encoding_list = ['CA_Name', 'Primary Type', 'Location_Category',
                 'Time_Risk', 'Season', 'Day_Type', 'Region']

# 4-4-1. Check values about encoding values
for col in encoding_list:
  unique_count = chicago_ml[col].nunique()
  print(f"{col}: {unique_count}")

chicago_ml = pd.get_dummies(chicago_ml, columns=encoding_list, drop_first=True)

print(chicago_ml.shape)

# 4-5. Create Target
from sklearn.preprocessing import LabelEncoder

label_encoder = LabelEncoder()
chicago_ml['Target'] = label_encoder.fit_transform(chicago_ml['Crime_Category'])

print(chicago_ml['Target'].value_counts().sort_index())

for i, col in enumerate(chicago_ml.columns):
  print(f"{i}: {col}")

# 4-5. Prepare for ML
exclued_feature = ['Crime_Category', 'Target']
features_col = [col for col in chicago_ml.columns if col not in exclued_feature]

x = chicago_ml[features_col]
y = chicago_ml['Target']

from sklearn.model_selection import train_test_split

X_temp, X_test, Y_temp, Y_test = train_test_split(x, y, test_size=0.2, random_state=42)
X_train, X_val, Y_train, Y_val = train_test_split(X_temp, Y_temp, test_size=0.25, random_state=42)

print(f"Train: {X_train.shape}")
print(f"Val: {X_val.shape}")
print(f"Test: {X_test.shape}")

# 5. LGBM
import lightgbm as lgb
import time
from sklearn.metrics import accuracy_score, f1_score

# Basic LGBM model
lgb_basic = lgb.LGBMClassifier(
    objective='multiclass',
    num_class=6,
    n_estimators=100,
    max_depth=6,
    learning_rate=0.1,
    random_state=42,
    verbose=-1
)

# Train Model
start_time = time.time()
lgb_basic_model = lgb_basic.fit(X_train, Y_train)
lgb_basic_train_time = time.time() - start_time

# Prediction
lgb_basic_train_pred = lgb_basic_model.predict(X_train)
lgb_basic_val_pred = lgb_basic_model.predict(X_val)

# Evaluation
lgb_basic_train_acc = accuracy_score(Y_train, lgb_basic_train_pred)
lgb_basic_val_acc = accuracy_score(Y_val, lgb_basic_val_pred)
lgb_basic_train_f1 = f1_score(Y_train, lgb_basic_train_pred, average='weighted')
lgb_basic_val_f1 = f1_score(Y_val, lgb_basic_val_pred, average='weighted')

# Overfitting
lgb_basic_overfitting = lgb_basic_train_acc - lgb_basic_val_acc

# result
print(f'Traing Time:{lgb_basic_train_time:.2f}second')
print(f'Train Accuracy: {lgb_basic_train_acc:.4f}')
print(f'Validation Accuracy: {lgb_basic_val_acc:.4f}')
print(f'Train F1: {lgb_basic_train_f1:.4f}')
print(f'Validation F1: {lgb_basic_val_f1:.4f}')
print(f'Overfitting Degree: {lgb_basic_overfitting:.4f}')

# Data leakage investigation
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
import lightgbm as lgb
import pandas as pd

# Test current accuracy
X_test = chicago_ml[features_col]
X_train, X_val, y_train, y_val = train_test_split(X_test, y, test_size=0.2, random_state=42, stratify=y)

test_model = lgb.LGBMClassifier(n_estimators=50, random_state=42, verbose=-1)
test_model.fit(X_train, y_train)
current_acc = accuracy_score(y_val, test_model.predict(X_val))

print(f"Current accuracy: {current_acc:.4f}")

if current_acc > 0.95:
   # Check Target-Crime_Category mapping
   mapping = pd.crosstab(chicago_ml['Target'], chicago_ml['Crime_Category'], normalize='index')
   if (mapping.max(axis=1) == 1.0).all():
       print("Perfect Target-Crime_Category mapping detected")

   # Find Primary Type leakage
   primary_features = [col for col in features_col if 'Primary Type_' in col]
   print(f"Leakage features ({len(primary_features)}):")
   print(primary_features)

# Reselect feature

excluded_features = ['Crime_Category', 'Target']

# Primary Type 피처들 추가
for col in chicago_ml.columns:
   if 'Primary Type_' in col:
       excluded_features.append(col)

features_col = [col for col in chicago_ml.columns if col not in excluded_features]
x = chicago_ml[features_col]
y = chicago_ml['Target']

from sklearn.model_selection import train_test_split

X_temp, X_test, Y_temp, Y_test = train_test_split(x, y, test_size=0.2, random_state=42)
X_train, X_val, Y_train, Y_val = train_test_split(X_temp, Y_temp, test_size=0.25, random_state=42)

print(f"Train: {X_train.shape}")
print(f"Val: {X_val.shape}")
print(f"Test: {X_test.shape}")

# 5. LGBM
import lightgbm as lgb
import time
from sklearn.metrics import accuracy_score, f1_score

# Basic LGBM model
lgb_basic = lgb.LGBMClassifier(
    objective='multiclass',
    num_class=6,
    n_estimators=100,
    max_depth=6,
    learning_rate=0.1,
    random_state=42,
    verbose=-1
)

# Train Model
start_time = time.time()
lgb_basic_model = lgb_basic.fit(X_train, Y_train)
lgb_basic_train_time = time.time() - start_time

# Prediction
lgb_basic_train_pred = lgb_basic_model.predict(X_train)
lgb_basic_val_pred = lgb_basic_model.predict(X_val)

# Evaluation
lgb_basic_train_acc = accuracy_score(Y_train, lgb_basic_train_pred)
lgb_basic_val_acc = accuracy_score(Y_val, lgb_basic_val_pred)
lgb_basic_train_f1 = f1_score(Y_train, lgb_basic_train_pred, average='weighted')
lgb_basic_val_f1 = f1_score(Y_val, lgb_basic_val_pred, average='weighted')

# Overfitting
lgb_basic_overfitting = lgb_basic_train_acc - lgb_basic_val_acc

# result
print(f'Traing Time:{lgb_basic_train_time:.2f}second')
print(f'Train Accuracy: {lgb_basic_train_acc:.4f}')
print(f'Validation Accuracy: {lgb_basic_val_acc:.4f}')
print(f'Train F1: {lgb_basic_train_f1:.4f}')
print(f'Validation F1: {lgb_basic_val_f1:.4f}')
print(f'Overfitting Degree: {lgb_basic_overfitting:.4f}')

# 5-1. LGBM with HyperOpt
from hyperopt import fmin, tpe, hp, Trials, STATUS_OK
from sklearn.model_selection import cross_val_score
from sklearn.metrics import accuracy_score, f1_score, classification_report
import warnings
import time

space = {
   'n_estimators': hp.choice('n_estimators', [100, 200, 300, 500]),
   'max_depth': hp.choice('max_depth', [3, 4, 5, 6, 7, 8]),
   'learning_rate': hp.uniform('learning_rate', 0.01, 0.3),
   'min_child_samples': hp.choice('min_child_samples', [10, 20, 30, 50]),
   'subsample': hp.uniform('subsample', 0.6, 1.0),
   'colsample_bytree': hp.uniform('colsample_bytree', 0.6, 1.0),
   'reg_alpha': hp.uniform('reg_alpha', 0, 1),
   'reg_lambda': hp.uniform('reg_lambda', 0, 1)
}

def objective(params):
   params['n_estimators'] = int(params['n_estimators'])
   params['max_depth'] = int(params['max_depth'])
   params['min_child_samples'] = int(params['min_child_samples'])

   model = lgb.LGBMClassifier(
       objective='multiclass',
       num_class=6,
       class_weight='balanced',
       random_state=42,
       verbose=-1,
       n_jobs=-1,
       **params
   )

   try:
       cv_scores = cross_val_score(
           model, X_train, Y_train, cv=2, scoring='f1_weighted', n_jobs=-1
       )
       return {'loss': 1 - cv_scores.mean(), 'status': STATUS_OK}
   except Exception as e:
       return {'loss': 1, 'status': STATUS_OK}

trials = Trials()
best = fmin(
   fn=objective,
   space=space,
   algo=tpe.suggest,
   max_evals=20,
   trials=trials,
   verbose=True
)

print(best)

# Model with best_params
best_params = {
   'n_estimators': int(best['n_estimators']),
   'max_depth': int(best['max_depth']),
   'min_child_samples': int(best['min_child_samples']),
   'learning_rate': best['learning_rate'],
   'subsample': best['subsample'],
   'colsample_bytree': best['colsample_bytree'],
   'reg_alpha': best['reg_alpha'],
   'reg_lambda': best['reg_lambda'],
   'objective': 'multiclass',
   'num_class': 6,
   'class_weight': 'balanced',
   'random_state': 42,
   'verbose': -1,
   'n_jobs': -1
}

start_time = time.time()
lgbm_optimized = lgb.LGBMClassifier(**best_params)
lgbm_optimized.fit(
   X_train, Y_train,
   eval_set=[(X_train, Y_train), (X_val, Y_val)],
   eval_names=['train', 'val'],
   callbacks=[lgb.early_stopping(100), lgb.log_evaluation(100)]
)
lgbmopt_train_time = time.time() - start_time

lgbmopt_train_pred = lgbm_optimized.predict(X_train)
lgbmopt_val_pred = lgbm_optimized.predict(X_val)
lgbmopt_test_pred = lgbm_optimized.predict(X_test)

lgbmopt_train_acc = accuracy_score(Y_train, lgbmopt_train_pred)
lgbmopt_val_acc = accuracy_score(Y_val, lgbmopt_val_pred)
lgbmopt_test_acc = accuracy_score(Y_test, lgbmopt_test_pred)

lgbmopt_train_f1 = f1_score(Y_train, lgbmopt_train_pred, average='weighted')
lgbmopt_val_f1 = f1_score(Y_val, lgbmopt_val_pred, average='weighted')
lgbmopt_test_f1 = f1_score(Y_test, lgbmopt_test_pred, average='weighted')

print(f"Training Time: {lgbmopt_train_time:.2f} seconds")
print(f"Train Accuracy: {lgbmopt_train_acc:.4f}")
print(f"Validation Accuracy: {lgbmopt_val_acc:.4f}")
print(f"Test Accuracy: {lgbmopt_test_acc:.4f}")
print(f"Train F1: {lgbmopt_train_f1:.4f}")
print(f"Validation F1: {lgbmopt_val_f1:.4f}")
print(f"Test F1: {lgbmopt_test_f1:.4f}")
print(f"Overfitting: {lgbmopt_train_acc - lgbmopt_val_acc:.4f}")

print(classification_report(Y_test, lgbmopt_test_pred))

# 6. XGBoost
import xgboost as xgb
import time
from sklearn.metrics import accuracy_score, f1_score

# XGB bascic
xgb_basic = xgb.XGBClassifier(
    objective='multi:softprob',
    num_class = 6,
    n_estimators = 100,
    max_depth = 6,
    learning_rate = 0.1,
    random_state = 42,
    min_child_weight = 1,
    subsample = 1.0,
    colsample_bytree = 1.0,
    reg_alpha = 0,
    reg_lambda = 0,
    eval_metric = 'mlogloss'
)

# Train_model
start_time = time.time()
xgb_basic_model = xgb_basic.fit(X_train, Y_train)
xgb_basic_train_time = time.time() - start_time

# prediction
xgb_basic_train_pred = xgb_basic_model.predict(X_train)
xgb_basic_val_pred = xgb_basic_model.predict(X_val)

# Evaluation
xgb_basic_train_acc = accuracy_score(Y_train, xgb_basic_train_pred)
xgb_basic_val_acc = accuracy_score(Y_val, xgb_basic_val_pred)
xgb_basic_train_f1 = f1_score(Y_train, xgb_basic_train_pred, average='weighted')
xgb_basic_val_f1 = f1_score(Y_val, xgb_basic_val_pred, average='weighted')

# Overfitting
xgb_basic_overfitting = xgb_basic_train_acc - xgb_basic_val_acc

# result
print(f'Traing Time:{xgb_basic_train_time:.2f}second')
print(f'Train Accuracy: {xgb_basic_train_acc:.4f}')
print(f'Validation Accuracy: {xgb_basic_val_acc:.4f}')
print(f'Train F1: {xgb_basic_train_f1:.4f}')
print(f'Validation F1: {xgb_basic_val_f1:.4f}')
print(f'Overfitting Degree: {xgb_basic_overfitting:.4f}')

# 6-1. XGBoost_HyperOpt
from hyperopt import fmin, tpe, hp, Trials, STATUS_OK
from sklearn.model_selection import cross_val_score
from sklearn.metrics import accuracy_score, f1_score, classification_report
import xgboost as xgb
import time

# Define choice lists
n_estimators_choices = [100, 200, 300, 500]
max_depth_choices = [3, 4, 5, 6, 7, 8]
min_child_weight_choices = [1, 5, 10, 20]

space = {
    'n_estimators': hp.choice('n_estimators', n_estimators_choices),
    'max_depth': hp.choice('max_depth', max_depth_choices),
    'min_child_weight': hp.choice('min_child_weight', min_child_weight_choices),
    'learning_rate': hp.uniform('learning_rate', 0.01, 0.3),
    'subsample': hp.uniform('subsample', 0.6, 1.0),
    'colsample_bytree': hp.uniform('colsample_bytree', 0.6, 1.0),
    'reg_alpha': hp.uniform('reg_alpha', 0, 1),
    'reg_lambda': hp.uniform('reg_lambda', 0, 1)
}

def objective(params):
    model = xgb.XGBClassifier(random_state=42, **params)
    cv_scores = cross_val_score(model, X_train, Y_train, cv=2, scoring='f1_weighted')
    return {'loss': 1 - cv_scores.mean(), 'status': STATUS_OK}

# Hyperparameter optimization
trials = Trials()
best = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=20, trials=trials)

# Extract best parameters
best_params = {
    'n_estimators': n_estimators_choices[best['n_estimators']],
    'max_depth': max_depth_choices[best['max_depth']],
    'min_child_weight': min_child_weight_choices[best['min_child_weight']],
    'learning_rate': best['learning_rate'],
    'subsample': best['subsample'],
    'colsample_bytree': best['colsample_bytree'],
    'reg_alpha': best['reg_alpha'],
    'reg_lambda': best['reg_lambda'],
    'random_state': 42
}

print("=== XGBoost Optimized Training ===")
start_time = time.time()

# Train optimized model
xgb_optimized = xgb.XGBClassifier(**best_params)
xgb_optimized.fit(X_train, Y_train)

training_time = time.time() - start_time

# Predictions
xgb_train_pred = xgb_optimized.predict(X_train)
xgb_val_pred = xgb_optimized.predict(X_val)
xgb_test_pred = xgb_optimized.predict(X_test)

# Metrics
xgbopt_train_acc = accuracy_score(Y_train, xgb_train_pred)
xgbopt_val_acc = accuracy_score(Y_val, xgb_val_pred)
xgbopt_test_acc = accuracy_score(Y_test, xgb_test_pred)

xgbopt_train_f1 = f1_score(Y_train, xgb_train_pred, average='weighted')
xgbopt_val_f1 = f1_score(Y_val, xgb_val_pred, average='weighted')
xgbopt_test_f1 = f1_score(Y_test, xgb_test_pred, average='weighted')

# Results
print(f"Training Time: {training_time:.2f} seconds")
print(f"Train Accuracy: {xgbopt_train_acc:.4f} | F1: {xgbopt_train_f1:.4f}")
print(f"Val Accuracy: {xgbopt_val_acc:.4f} | F1: {xgbopt_val_f1:.4f}")
print(f"Test Accuracy: {xgbopt_test_acc:.4f} | F1: {xgbopt_test_f1:.4f}")
print(f"Overfitting: {xgbopt_train_acc - xgbopt_val_acc:.4f}")

print("\n=== Classification Report (Test Set) ===")
print(classification_report(Y_test, xgb_test_pred))

# 7. Visualize and Compare Models (Final Fixed Version)
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix, classification_report

# 7-1. Model Comparison
def plot_model_comparison():
    models = ['RF', 'LGBM', 'XGB']
    accuracies = [rf_best_val_acc, lgbmopt_val_acc, xgbopt_val_acc]
    f1_scores = [rf_best_val_f1, lgbmopt_val_f1, xgbopt_val_f1]

    plt.figure(figsize=(10, 5))

    plt.subplot(1, 2, 1)
    plt.bar(models, accuracies, color=['blue', 'orange', 'green'])
    plt.title('Validation Accuracy')
    plt.ylabel('Accuracy')
    for i, v in enumerate(accuracies):
        plt.text(i, v + 0.01, f'{v:.3f}', ha='center')

    plt.subplot(1, 2, 2)
    plt.bar(models, f1_scores, color=['blue', 'orange', 'green'])
    plt.title('Validation F1-Score')
    plt.ylabel('F1-Score')
    for i, v in enumerate(f1_scores):
        plt.text(i, v + 0.01, f'{v:.3f}', ha='center')

    plt.tight_layout()
    plt.show()

# 7-2. Feature Importance
def feature_importance():
    rf_importance = rf_best_model.featureImportances.toArray()
    lgbm_importance = lgbm_optimized.feature_importances_
    xgb_importance = xgb_optimized.feature_importances_
    feature_names = features_col

    rf_top10_idx = np.argsort(rf_importance)[-10:]
    lgbm_top10_idx = np.argsort(lgbm_importance)[-10:]
    xgb_top10_idx = np.argsort(xgb_importance)[-10:]

    plt.figure(figsize=(18, 6))

    plt.subplot(1, 3, 1)
    rf_top10_features = [feature_names[i] for i in rf_top10_idx]
    rf_top10_importance = rf_importance[rf_top10_idx]

    plt.barh(range(10), rf_top10_importance, color='blue')
    plt.yticks(range(10), rf_top10_features)
    plt.xlabel('Importance')
    plt.title('RF Top 10 Features')

    plt.subplot(1, 3, 2)
    lgbm_top10_features = [feature_names[i] for i in lgbm_top10_idx]
    lgbm_top10_importance = lgbm_importance[lgbm_top10_idx]

    plt.barh(range(10), lgbm_top10_importance, color='orange')
    plt.yticks(range(10), lgbm_top10_features)
    plt.xlabel('Importance')
    plt.title('LGBM Top 10 Features')

    plt.subplot(1, 3, 3)
    xgb_top10_features = [feature_names[i] for i in xgb_top10_idx]
    xgb_top10_importance = xgb_importance[xgb_top10_idx]

    plt.barh(range(10), xgb_top10_importance, color='green')
    plt.yticks(range(10), xgb_top10_features)
    plt.xlabel('Importance')
    plt.title('XGBoost Top 10 Features')

    plt.tight_layout()
    plt.show()

# 7-3. Confusion Matrix
def plot_confusion_matrix():
    rf_predictions = rf_best_val_pred.select('prediction').rdd.flatMap(lambda x: x).collect()
    rf_true_labels = rf_best_val_pred.select('label').rdd.flatMap(lambda x: x).collect()

    rf_cm = confusion_matrix(rf_true_labels, rf_predictions)
    lgbm_cm = confusion_matrix(Y_val, lgbmopt_val_pred)
    xgb_cm = confusion_matrix(Y_val, xgb_val_pred)

    class_names = ['DRUG', 'PROPERTY', 'PUBLIC_ORDER', 'SEX_CRIME', 'VIOLENT', 'WEAPONS']

    plt.figure(figsize=(18, 5))

    plt.subplot(1, 3, 1)
    sns.heatmap(rf_cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=class_names, yticklabels=class_names)
    plt.title('RF Confusion Matrix')
    plt.xlabel('Predicted')
    plt.ylabel('Actual')

    plt.subplot(1, 3, 2)
    sns.heatmap(lgbm_cm, annot=True, fmt='d', cmap='Oranges',
                xticklabels=class_names, yticklabels=class_names)
    plt.title('LGBM Confusion Matrix')
    plt.xlabel('Predicted')
    plt.ylabel('Actual')

    plt.subplot(1, 3, 3)
    sns.heatmap(xgb_cm, annot=True, fmt='d', cmap='Greens',
                xticklabels=class_names, yticklabels=class_names)
    plt.title('XGBoost Confusion Matrix')
    plt.xlabel('Predicted')
    plt.ylabel('Actual')

    plt.tight_layout()
    plt.show()

# 7-4. Performance (Final Fixed Version)
def plot_class_performance():
    rf_predictions = rf_best_val_pred.select('prediction').rdd.flatMap(lambda x: x).collect()
    rf_true_labels = rf_best_val_pred.select('label').rdd.flatMap(lambda x: x).collect()

    rf_report = classification_report(rf_true_labels, rf_predictions, output_dict=True)
    lgbm_report = classification_report(Y_val, lgbmopt_val_pred, output_dict=True)
    xgb_report = classification_report(Y_val, xgb_val_pred, output_dict=True)

    # Debug: Print all available keys first
    print("RF report keys:", list(rf_report.keys()))
    print("LGBM report keys:", list(lgbm_report.keys()))
    print("XGB report keys:", list(xgb_report.keys()))

    # Find actual class keys (exclude 'accuracy', 'macro avg', 'weighted avg')
    rf_class_keys = [k for k in rf_report.keys() if k not in ['accuracy', 'macro avg', 'weighted avg']]
    lgbm_class_keys = [k for k in lgbm_report.keys() if k not in ['accuracy', 'macro avg', 'weighted avg']]
    xgb_class_keys = [k for k in xgb_report.keys() if k not in ['accuracy', 'macro avg', 'weighted avg']]

    print("RF class keys:", rf_class_keys)
    print("LGBM class keys:", lgbm_class_keys)
    print("XGB class keys:", xgb_class_keys)

    # Sort keys to ensure proper order (0, 1, 2, 3, 4, 5)
    rf_sorted_keys = sorted(rf_class_keys, key=lambda x: int(x) if str(x).isdigit() else float('inf'))
    lgbm_sorted_keys = sorted(lgbm_class_keys, key=lambda x: int(x) if str(x).isdigit() else float('inf'))
    xgb_sorted_keys = sorted(xgb_class_keys, key=lambda x: int(x) if str(x).isdigit() else float('inf'))

    print("Sorted keys - RF:", rf_sorted_keys[:6])
    print("Sorted keys - LGBM:", lgbm_sorted_keys[:6])
    print("Sorted keys - XGB:", xgb_sorted_keys[:6])

    class_names = ['DRUG', 'PROPERTY', 'PUBLIC_ORDER', 'SEX_CRIME', 'VIOLENT', 'WEAPONS']

    # Get F1 scores using actual sorted keys (take first 6)
    rf_f1 = [rf_report[key]['f1-score'] for key in rf_sorted_keys[:6]]
    lgbm_f1 = [lgbm_report[key]['f1-score'] for key in lgbm_sorted_keys[:6]]
    xgb_f1 = [xgb_report[key]['f1-score'] for key in xgb_sorted_keys[:6]]

    x = np.arange(len(class_names))
    width = 0.2

    plt.figure(figsize=(12, 6))
    plt.bar(x - width, rf_f1, width, label='RF', color='blue')
    plt.bar(x, lgbm_f1, width, label='LGBM', color='orange')
    plt.bar(x + width, xgb_f1, width, label='XGBoost', color='green')

    plt.xlabel('Crime Categories')
    plt.ylabel('F1-Score')
    plt.title('Class-wise F1-Score Comparison')
    plt.xticks(x, class_names, rotation=45)
    plt.legend()
    plt.tight_layout()
    plt.show()

# 7-5. Model Summary
def model_summary():
    print(f'Random Forest Accuracy: {rf_best_val_acc:.4f}, F1: {rf_best_val_f1:.4f}')
    print(f'LGBM Accuracy: {lgbmopt_val_acc:.4f}, F1: {lgbmopt_val_f1:.4f}')
    print(f'XGBoost Accuracy: {xgbopt_val_acc:.4f}, F1: {xgbopt_val_f1:.4f}')

# 7-6. Run Analysis
def run_analysis():
    plot_model_comparison()
    feature_importance()
    plot_confusion_matrix()
    plot_class_performance()
    model_summary()

run_analysis()

# 8. XGB
import joblib
joblib.dump(xgb_optimized, 'crime_prediction_model.pkl')

import pickle
with open('features_col.pkl', 'wb') as f:
    pickle.dump(features_col, f)

# Model, features download
from google.colab import files
files.download('crime_prediction_model.pkl')
files.download('features_col.pkl')